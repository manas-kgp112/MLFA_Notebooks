{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice to see you again. Let's start with Gradient Dascent today and then Stochastic Gradient Descent, Mini-Batch Stochastic Gradient Descent, Adaptive Gradient Descent.\n",
    "\n",
    "Too much Mathematics today, fasten your belt..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent : It is an optimization method which minimizes the error function of a particular learning model by selecting the best parameters automatically.\n",
    "\n",
    "So our goal is to minimize this function w.r.t. parameters. This function is known as error function or cost function (in some cases).\n",
    "\n",
    "![#](images/linear-regression-errorsum2.png \"Gradient Descent Error Function\")\n",
    "\n",
    "Let's plot the learning model function against the parameters (consider only 1 parameter for ease) (y = E(theta))\n",
    "\n",
    "![#](images/gradient-descent-plot.png \"Gradient Descent Plot\")\n",
    "\n",
    "The next step is to select any random set of parameters used in the model. There are no restrictions on selection of parameters.From the graph given above, it is evident that we have to modify the parameter so as to reach the local minima of the plot. It is done using updating the parameter.\n",
    "\n",
    "![#](images/gradient-descent-function-plot.png \"Gradient Descent Function Plot\")\n",
    "\n",
    "But the question arises how to update the parameter ?\n",
    "\n",
    "It is done using a mathematical function mentioned below .\n",
    "\n",
    "![#](images/gradient-descent-mathematics.png \"Gradient Descent Function\")\n",
    "\n",
    "Repeat updating the parameter until convergence (partial differentiation of E wrt parameter becomes equal to 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematics for Gradient Descent : Clarity over Concept\n",
    "\n",
    "We will look into the actual equation to update the parameter with measurebale quantities.\n",
    "\n",
    "First step is to partially differentiate the equation .\n",
    "\n",
    "1) ![#](images/gradient-descent-mathematics-1.png \"Step-1\")\n",
    "\n",
    "2) ![#](images/gradient-descent-mathematics-2.png \"Step-2\")\n",
    "\n",
    "Considering y(i) as constant and substituting eqn 2 in 1\n",
    "\n",
    "![#](images/gradient-descent-differential.png \"Differential Parameter\")\n",
    "\n",
    "This function is used to calculate the partial differential wrt parameters. for e.g.\n",
    "\n",
    "![#](images/gradient-descent-differential-example.png \"Differential Parameter Example\")\n",
    "\n",
    "Note: For each parameter (ùúΩ(ùíã )), we need to process all training samples. In other words, for k parameters and n training sample, we need (k * n) processing which posses a great problem in case of huge number of training samples.. What to do then? \n",
    "\n",
    "Stochastic gradient descent comes to our rescue !! ‚ÄúStochastic‚Äù, in plain terms means ‚Äúrandom‚Äù."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Graient Descent : \n",
    "\n",
    "When you change only parameter at a time, that's it!\n",
    "\n",
    "Mini Batch Gradient Descent : In this method, gradient is calculated on a sample batch of b training samples and not on the n training samples. (b < n)\n",
    "\n",
    "We will look into details of SGD and Mini-Batch SGD some other day :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations of Gradient Descent : \n",
    "\n",
    "1) Learning Rate(r) - The learning rate is a constant which we can select while constructing our model and it varies from case to case but usually is less than 1. Now considering very big learning rate for our model may lead to overshooting of updtaed parameter points whereas very small learning rate may lead to very small steps in updating the parameter.\n",
    "\n",
    "![#](images/small-learning-rate.png \"Small learning rate\") ![#](images/large-learning-rate.png \"Large learning rate\")\n",
    "\n",
    "The first image shows if the learning rate is too small and the seconf image shows if the learning rate is too large.\n",
    "\n",
    "How to overcome this problem? We have Adaptive Gradient Descent or Adgard to play the particular role!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive Gradient Descent/ADAGRAD : In this algorithm, the learning rate is kept changing for parameters unlike constant in case of Gradient Descent and SGD. The learning rate depends on it's previous gradients.\n",
    "\n",
    "So the gradient descent equation in case of Adagrad looks like this - \n",
    "\n",
    "![#](images/adgard.png \"Adgard Equation\")\n",
    "\n",
    "Here, in this equation \n",
    "\n",
    "![#](images/adgard-params.png \"Adgrad Parameters\")\n",
    "\n",
    "Let us take a look at what is actually G^(t) is !\n",
    "\n",
    "Let us consider a parameter ùúΩ(0) and t iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive Moment Estimation: ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for today. See you in next notebook !\n",
    "\n",
    "In net notebook we will learn about Deep Neural Networks.\n",
    "\n",
    "PS : Some extra material on Gradient Descent [here](advanved-gradient-descent.ipynb \"here\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da744e63d7114826029aa1cdcb8ffc532c4563260d851055c1d03876e527cfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
