{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Python Notebook of \"MLFA/Machine Learning Foundations and Applications\" course offered by Indian Institute of Technology, Kharagpur\n",
    "In this notebook we will look into what is machine learning and how it is useful in today's world.\n",
    "So let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is all about training computer device with n examples such that it can now predict output labels for those input values that it never came across.\n",
    "Objective of Machine Learning is to make predictions or decisions without being explicitly programmed to do so.\n",
    "\n",
    "\n",
    "For e.g. we store 10^6 exanples of price of house ($) against size of house (ft^2) and now let the machine predict the price of house for a random input that was not a part of the 10^6 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are majorly 4 types of learnings commonly called Supervised Learning, Unsupervised learning, Associateion learning and Reinforcement learning. In this notwbook we will be learning about supervised learning only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPERVISED LEARNING MODEL : Providing machine with both inputs and outputs for n examples and obtaining predicted value of (n+1)th input example. Supervised learning is all about mapping the inputs and outputs with a particular function/hypothesis i.e. [y = f(x)] \n",
    "\n",
    "Common terms to be learnt/understood before proceeding to Supervised Learning :\n",
    "1) Features - These are the parameters on which the output depends.\n",
    "For e.g. , the price of the house depends on size of the house (a1), number of bathrooms (n1), bedrooms (n2) and kitchen (n3) and also on the area of walls (a2) and also nearby factors such as distance from airport (d1), hospital (d2) etc. \n",
    "So the features/paramters that decide the price of the house are {a1, a2, n1, n2, n3, d1, d2}\n",
    "\n",
    "2) Ouput labels - Output value for particular input.\n",
    "\n",
    "3) Training Data - It is the data (present) that we feed into our machine in order to generate the best hypothesis for our dataset i.e. combination of features and output labels.\n",
    "\n",
    "4) Learning algorithm or hypothesis - It is a mathematical function that relates the input and output training dataset and then predicts further outputs for ny random input.\n",
    "Hypothesis [yi = f(xi)] for i = {1, 2, 3 .... n} \n",
    "\n",
    "5) Test Sample - It the input for which we want prediction from the learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![#](images/supervised-pictorial.png \"Supervised Pictorial Representation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F here is known as hypothesis or the function which predicts the output values for new input values\n",
    "\n",
    "There are two types of supervised learning :\n",
    "1) Regeression (continous output values) e.g. calulation of cgpa\n",
    "2) Classification (discrete output values) e.g. classification of products into categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION : Continous output prediction model i.e. output could be any real number not some specific points.\n",
    "\n",
    "2 Types : Linear (straight line | highest power of x is 1) and Non-linear (curve | highest power of x is n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Linear Regeression : This learning models plots a linear curve between the input and output labels [y = f(x)]\n",
    " \n",
    "![#](images/linear-regression.png \"Linear Regression Maths\")\n",
    "\n",
    "ques} Now the question is what are paramteres?\n",
    "\n",
    "ans} : When you plot the hypothesis, the output will de dependent on input by a multiple of some constant i.e.\n",
    "y = w0 + w1x1 + w2x2 .... + wnxn where w0, w1 ... wn are all paramteres (constants).\n",
    "\n",
    "ques} Now how to get parameters?\n",
    "\n",
    "ans} : Parameters are decided by us only but there is a mathematical approach called \"gradient descent\" to get correct parameters for our learning model which we will learn in further notebooks.\n",
    "\n",
    "\n",
    "We will now plot the graph for linear regression model.\n",
    "\n",
    "See how the linear plot covers maximum dataset points and this line is known as hypothesis of learning model which will predict output labels for any input. ![#](images/linear-regression-plot.png \"Linear Regression Plot\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after all this what is the purpose of creating a linear regression learning model ?\n",
    "\n",
    "In order to get best predictions of our test cases !\n",
    "This is achieved using calculating 'error function' of the particular learning model 'E(x)' which tells how accurate our learning model is to actual values.\n",
    "\n",
    "![#](images/linear-regression-error.png \"Linear Regression Error Function\")\n",
    "\n",
    "This is error of just one random ith input dataset. We need to sum the error over each input available in the training data.\n",
    "\n",
    "![#](images/linear-regression-errorsum.png \"Linear Regression Error Sum Function\")\n",
    "\n",
    "\n",
    "If your error sum function (Et) is too high it means your model is not fit for the training data and will not give accurate predictions. So we need to minimize the error function.\n",
    "\n",
    "Welcome 'Gradient Descent' !\n",
    "Before proceeding to Gradient Descent and it's applications, here is a quick recap to Differential Calculus required for learning Gradient Descent.\n",
    "\n",
    "[Recap : Differential Calculus](images/revision-to-calculus.ipynb)\n",
    "\n",
    "As now you have revised the concepts of differential calculus, we will start with Graident Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent : It is an optimization method which minimizes the error function (local minima) of a particular learning model by selecting the best parameters automatically.\n",
    "\n",
    "We will look into more detail about Gradient Descent in further notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting : Limitation of Linear Regression Model\n",
    "\n",
    "The model fails to capture the structure of the training set which results in very high error in predictions.\n",
    "\n",
    "![#](images/linear-regression-failure.png \"Linear regression Limitation\")\n",
    "\n",
    "To overcome this we came up with another kind of regression type i.e. non-linear regression learning in which the plot curves along the structure of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Non-Linear Regression : This learning model plots a nth order curve between input and output data sets y = f(x)\n",
    "\n",
    "![#](images/non-linear-regression.png \"Non Linear Regression Math\")\n",
    "\n",
    "We will now plot the graph for linear regression model.\n",
    "\n",
    "See how the non-linear curve covers maximum dataset in this case\n",
    "![#](images/non-linear-regression-plot.png \"Linear Regression Plot\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting : Limitation of Non-Linear Regression Model\n",
    "\n",
    "We don't know where to stop n (highest order of x in non-linear regression models). Very high n may lead to very huge training time and also lead to overfitting i.e. model just remembers the dataset but has no predective power.\n",
    "\n",
    "![#](images/non-linear-regression-failure.png \"Non Linear Regression Model Limitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much for one notebook ! Let's end it here.\n",
    "\n",
    "In next notebook we will learn what is locally weighted regression. classification and K Nearest Neighbour (K-NN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for more deailed content on these topics ?\n",
    "\n",
    "[Regression : A supervised learning method](lecture1-adv.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da744e63d7114826029aa1cdcb8ffc532c4563260d851055c1d03876e527cfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
